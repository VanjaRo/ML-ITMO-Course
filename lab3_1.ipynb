{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression lab 3.1-3.4",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkTpaRRWZNc3"
      },
      "source": [
        "# Линейная регрессия\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro-ttLpiZNdC"
      },
      "source": [
        "Линейные методы предполагают, что между признаками объекта и целевой переменной существует линейная зависимость, то есть:\n",
        "$$ \\hat{y} = w_1 x_1 + w_2 x_2 + ... + w_k x_k + b,$$\n",
        "где $\\hat{y}$ - целевая переменная (что мы хотим предсказать), $x_i$ - i-ый признак объекта $x$, $w_i$ - вес $i$-го признака, $b$ - bias (смещение, свободный член).\n",
        "\n",
        "В задаче линейной регрессии $\\hat{y}$ - это действительное число.\n",
        "\n",
        "Часто для упрощения записи вводят дополнительный фиктивный признак $x_0$, который всегда равен 1, тогда bias - вес этого признака. В этом случае формула может быть записана как скалярное произведение:\n",
        "$$ \\hat{y} = <w, x> $$\n",
        "\n",
        "В матричной форме формулу можно переписать следующим образом:\n",
        "$$ \\hat{y} = Xw,$$\n",
        "$\\hat{y}$ - вектор значений целевой переменной размера $n$, $X$ - матрица значений признаков объектов размера $n \\times k$, w - вектор весов размера $k$. То есть в наших данных имеется $n$ объектов, каждый их которых описан $k$ признаками.\n",
        "\n",
        "Таким образом, в матричной форме модель задаётся следующим образом:\n",
        "$$ y = Xw + \\epsilon$$ \n",
        "\n",
        "Важно отметить, что параметрами этой модели являются веса $w$. Когда говорят об обучении какого-либо алгоритма машинного обучения, как правило, имеют в виду настройку весов, т.е. параметров модели.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixnX1G4yDVcG"
      },
      "source": [
        "На практике $\\hat{y} $ может отличается от реальных значений, которые принимает целевая переменная $y$. Разницу между реальным значением и предсказанным, обозначим как $\\epsilon$ - вектор значений случайной переменной, соответствующая случайной, непрогнозируемой ошибке модели. Ограничения, которые накладываются на эту модель:\n",
        "* математическое ожидание случайных ошибок $\\epsilon$ равно нулю,\n",
        "* дисперсия случайных ошибок одинакова и конечна,\n",
        "* случайные ошибки не скоррелированы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJyN9MkMDTod"
      },
      "source": [
        "Один из способов вычислить значения параметров модели, давно знаком - это наименьших квадратов, который минимизирует среднеквадратичную ошибку между реальным значением зависимой переменной и прогнозом, выданным моделью. Решение по методу наименьших квадратов дает:\n",
        "$$ w = (X^TX)^{-1}X^TY $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5HVNycSZNc5"
      },
      "source": [
        "Загрузим необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrhz2sFvZNc7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFQqRj1lZNdg"
      },
      "source": [
        "## Оценка результатов\n",
        "\n",
        "Чтобы оценить качество работы алгоритма нам необходимо применяют разные метрики. Наиболее частые метрики средневадратичная и средняя абсолютная ошибки. Вычислим эти метрики на обучающей и на тестовой выборках. \n",
        "\n",
        " * *mean_absolute_error* - средняя абсолютная ошибка $|y_i - \\hat{y}_i|$\n",
        " * *mean_squared_error* - средняя квадратичная ошибка $(y_i - \\hat{y}_i)^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sEDF-oXRsVw"
      },
      "source": [
        "## Задание 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aStEfJYSZNdE"
      },
      "source": [
        "Пример 1. Сгенерируем искусственные данные. Сначала поработаем с простейшим одномерным случаем, когда у нас значение $y$ будет зависеть только от одного значения $x$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3tzSTkrZNdF"
      },
      "source": [
        "def generate_data(n_points=20):\n",
        "  \"\"\"\n",
        "    Принимает на вход n_points точек \n",
        "    Возвращает данные для обучения и теста\n",
        "  \"\"\"\n",
        "  X = np.linspace(-5, 5, n_points)\n",
        "  y = 10 * X - 7\n",
        "\n",
        "  X_train = X[0::2].reshape(-1, 1)\n",
        "  y_train = y[0::2] + np.random.randn(int(n_points/2)) * 10\n",
        "\n",
        "  X_test = X[1::2].reshape(-1, 1)\n",
        "  y_test = y[1::2] + np.random.randn(int(n_points/2)) * 10\n",
        "\n",
        "  print(f'Generated {len(X_train)} train samples and {len(X_test)} test samples')\n",
        "  return X, X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnYHO2TjZNdJ"
      },
      "source": [
        "X, X_train, y_train, X_test, y_test = generate_data(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0l76cbaKzYg"
      },
      "source": [
        "### Реализуйте настройку w и b с помощью рассмотренного выше метода наименьших квадратов.\n",
        "### Найдите значения метрик MSE и MAE. Сравните с результатами из sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luGJoQXHRzu7"
      },
      "source": [
        "## Задание 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKKQZDzWMv-j"
      },
      "source": [
        "Пример 2. Не всегда в задаче регрессии в качестве решения выступает прямая, как в предыдущем случае. Рассмотрим ещё один пример, в котором у объектов всё ещё один признак. Но теперь мы будм брать случайную точку на синусоиде и добавлять к ней шум — таким образом получим целевую переменную, признаком в этом случае будет координата $x$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aULennJThZxH"
      },
      "source": [
        "def generate_wave_set(n_support=1000, n_train=25, std=0.3):\n",
        "    data = {}\n",
        "    # выберем некоторое количество точек из промежутка от 0 до 2*pi\n",
        "    data['support'] = np.linspace(0, 2*np.pi, num=n_support)\n",
        "    # для каждой посчитаем значение sin(x) + 1\n",
        "    # это будет ground truth\n",
        "    data['values'] = np.sin(data['support']) + 1\n",
        "    # из support посемплируем некоторое количество точек с возвратом, это будут признаки\n",
        "    data['x_train'] = np.sort(np.random.choice(data['support'], size=n_train, replace=True))\n",
        "    # опять посчитаем sin(x) + 1 и добавим шум, получим целевую переменную\n",
        "    data['y_train'] = np.sin(data['x_train']) + 1 + np.random.normal(0, std, size=data['x_train'].shape[0])\n",
        "    return data\n",
        "\n",
        "data = generate_wave_set(1000, 250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CBnODv1QYn_"
      },
      "source": [
        "### попробуйте реализовать настройку w и b с помощью рассмотренного выше метода наименьших квадратов.\n",
        "### Найдите значения метрик MSE и MAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9iBgsGVQyOD"
      },
      "source": [
        "Конечно, такое решение нас вряд ли может устроить. Нужно применить полинимиальную регрессию. Идея здесь такая. Каждый признак в исходную формулу может входить не только в первой степени, но и во второй, в третьей и так далее. То есть для случая, когда у нас только один признак:\n",
        "$$ \\hat{y} = w_1 x_1 + w_2 x_1^2 + ... + w_k x_1^k + b,$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95m0fULWR4m5"
      },
      "source": [
        "## Задание 3.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyzS3rlzSuDU"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "### Реализуйте полиномиальную регрессию. Сделайте визуализацию для полиномов разных степеней. \n",
        "### Полином какой степени подходит больше других? Почему?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feMIFS82ZNdn"
      },
      "source": [
        "# Реальный датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NVLc80wZNdn"
      },
      "source": [
        "Возьмём реальный набор данных Boston из sklearn.datasets. Этот датасет описывает средние цены на недвижимость в районах Бостона в тысячах долларов.\n",
        "\n",
        "Примеры признаков объектов недвижимости: количество преступлений на душу населения, процент старых домов в районе, количество учеников на одного учителя и т.д. Обратите внимание на то, что данные уже оцифрованы там, где изначально признаки были качественными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMC-plFGZNdo"
      },
      "source": [
        "Загрузим датасет, выведем информацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6sApHcZNdo"
      },
      "source": [
        "from sklearn.datasets import load_boston\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBgnP7HcZNdq"
      },
      "source": [
        "house_data = load_boston()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjL3jxlqgHWs"
      },
      "source": [
        "## Задание 3.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbTQGLKagJN5"
      },
      "source": [
        "### оставьте в наборе данных только 7 наиболее значимых признаков\n",
        "### настройте параметры линейной регрессии и сравните метрики качества (MSE и MAE) для полного датасета и усечённого"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}